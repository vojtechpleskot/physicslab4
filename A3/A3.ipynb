{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the string \"Your Name\" and \"Date of measurement\" with the appropriate values.\n",
    "\n",
    "from header import header\n",
    "_ = header(student=\"Your Name\", date=\"Date of measurement\", task_no=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of elements based on their characteristic X-rays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "When the excited state of the atomic envelope de-excites, it produces X-rays. This radiation is characteristic of the element [1], and determining its energy and intensity allows for a qualitative and quantitative analysis of the material under investigation. The atomic envelope can be excited in various ways. The so-called X-ray fluorescence method uses gamma-quanta's interaction with the atomic envelope's electrons. The electrons are knocked out of the envelope by a photoelectric effect, thereby exciting it. It de-excites by emitting X-rays characteristic of the element.\n",
    "\n",
    "Our experiment measures the X-ray spectra produced when different samples are irradiated with gamma radiation from a radioactive source. Transitions between the different levels of a given atom appear as peaks in our spectra. Energies at which the peaks are located are used to identify the sample material. If we also determine the intensity of the peaks, we can quantify the sample's composition. The intensity of the characteristic X-rays depends on the geometry of the experiment, the thickness of the sample, its composition, the intensity of the excitation radiation, and the properties of the detector - the method sensitivity is mostly determined by detector's energy resolution and efficiency.\n",
    "\n",
    "\n",
    "The gamma-ray source used in our experiment is $^{241}\\mathrm{Am}$. Alpha decay of this isotope produces $^{237}\\mathrm{Np}$, whose nucleus is excited. The most intense gamma line of the nucleus' de-excitation has an energy of 59.5 keV [2]. In addition, L-series X-ray photons in the 10-20 keV energy region originate from the atomic envelope of the daughter $^{237}\\mathrm{Np}$ atom.\n",
    "\n",
    "The radioactive source is placed in a holder next to the detector, the measured samples of various materials are placed below the source. We detect the characteristic X-rays by a semiconductor spectrometer consisting of a germanium detector with a beryllium window, a charge-sensitive preamplifier, a linear amplifier, a high-voltage source and a PC-based channel converter. Approximately 3.5 kV voltage is applied to the detector.\n",
    "\n",
    "The energy resolution of our gamma-spectrometer is FWHM ≈ 0.9 keV in the 5-60 keV energy range. Because of this poor resolution and a thick beryllium window enclosing the detector, registration of radiation with energies $E_\\gamma < 4\\ \\mathrm{keV}$ is impossible. Therefore, identifying elements with a proton number $Z < 20$ is practically impossible, and the whole analysis might be inaccurate.\n",
    "\n",
    "Given the energies of X-ray radiation and the densities of the samples used, it is clear that we are examining their composition to a depth of several tens to a few hundred micrometers. From a depth greater than three half-value layers, at most a few percent of the X-ray radiation will escape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "We calibrate the gamma spectrometer using the $^{241}\\mathrm{Am}$ radioactive source. We then measure the X-ray spectra of various materials, process these spectra, and identify the material or composition of the sample using the table of characteristic X-ray energies. We select the exposure time for each measurement to ensure a measurement uncertainty of less than 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement results\n",
    "\n",
    "$\\color{red}{\\textbf{Task:}}$ Calibrate the spectrometer using the $^{241}\\mathrm{Am}$ radioactive source. Use the tabulated energies of the singlet peaks. Determine the systematic uncertainty of the calibration using the 17.8 keV multiplet. Discuss the calibration results and its uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Solution:}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ The measured samples are metals at first glance. Let us assume that they are either single-element samples or binary alloys, with atomic numbers in the range $26 \\leq Z \\leq 52$. Determine the chemical elements in the single-element samples. Create a table with the sample number, the measured peak energy, Net Area, and FWHM, the activity (net counts in the peak per second), the uncertainty on the activity, the identified element, and its proton number. Each row in the table corresponds to one spectral line of the given sample. Also, determine the chemical composition of the multi-element samples - alloys. Quote them in the table also (one row per each spectral line of each element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "### TODO: add Net Area and FWHM to the example data below. The values of one are placeholders.\n",
    "###################################################################################################\n",
    "\n",
    "# Insert your code here\n",
    "# Store the data in a list of lists like in this example:\n",
    "# data = [\n",
    "#     [1,   8.11, 1, 1, 34.2 , 0.2 , \"K_a+b\", \"Cu\", 29],  # Cu = 29\n",
    "#     [2,  25.29, 1, 1, 97.9 , 0.6 , \"K_a\"  , \"Sn\", 50],   # Sn = 50\n",
    "#     ...\n",
    "# ]\n",
    "# The elements of the inner lists are:\n",
    "#   [\"Sample\", \"Energy [keV]\", \"Net Area\", \"FWHM [keV]\", \"Intensity [1/s]\", \"Intensity unc. [1/s]\", \"Line\", \"Element\", \"Z\"]\n",
    "\n",
    "data = [\n",
    "    [1,   8.11, 1, 1, 34.2 , 0.2 , \"K_a+b\", \"Cu\", 29],   # Cu = 29\n",
    "    [2,  25.29, 1, 1, 97.9 , 0.6 , \"K_a\"  , \"Sn\", 50],   # Sn = 50\n",
    "    [2,  28.61, 1, 1, 22.5 , 0.4 , \"K_b\"  , \"Sn\", 50],   # Sn = 50\n",
    "    [3,  20.25, 1, 1, 70.5 , 0.7 , \"K_a\"  , \"Rh\", 45],   # Rh = 45\n",
    "    [3,  22.83, 1, 1, 14.4 , 0.4 , \"K_b\"  , \"Rh\", 45],   # Rh = 45\n",
    "    [4,  10.59, 1, 1, 18.7 , 0.4 , \"L_a\"  , \"Pb\", 82],   # Pb = 82\n",
    "    [4,  12.68, 1, 1, 20.6 , 0.4 , \"L_b\"  , \"Pb\", 82],   # Pb = 82\n",
    "    [5,   8.40, 1, 1, 5.49 , 0.19, \"K_a+b\", \"Cu\", 29],   # Cu = 29\n",
    "    [5,  22.18, 1, 1, 47.0 , 0.3 , \"K_a\"  , \"Ag\", 47],   # Ag = 47\n",
    "    [5,  25.05, 1, 1, 13.4 , 0.2 , \"K_b\"  , \"Ag\", 47],   # Ag = 47\n",
    "    [6,  15.80, 1, 1, 53.1 , 0.5 , \"K_a\"  , \"Zr\", 40],   # Zr = 40\n",
    "    [6,  17.71, 1, 1, 11.1 , 0.3 , \"K_b\"  , \"Zr\", 40],   # Zr = 40\n",
    "    [9,  17.50, 1, 1, 85.8 , 0.8 , \"K_a\"  , \"Mo\", 42],   # Mo = 42\n",
    "    [9,  19.71, 1, 1, 16.5 , 0.4 , \"K_b\"  , \"Mo\", 42],   # Mo = 42\n",
    "    [11, 23.19, 1, 1, 100.5, 1.0 , \"K_a\"  , \"Cd\", 48],   # Cd = 48\n",
    "    [11, 26.19, 1, 1, 27.4 , 0.7 , \"K_b\"  , \"Cd\", 48],   # Cd = 48\n",
    "    [10,  8.68, 1, 1, 25.5 , 0.4 , \"K_a+b\", \"Zn\", 30],   # Zn = 30\n",
    "    [12,  6.41, 1, 1, 12.3 , 0.8 , \"K_a+b\", \"Fe\", 26],   # Fe = 26\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Create a pandas DataFrame from the list data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the data and set the column names\n",
    "df = pd.DataFrame(data, columns=[\"Sample\", \"Energy [keV]\", \"Net Area\", \"FWHM [keV]\", \"Intensity [1/s]\", \"Intensity unc. [1/s]\", \"Line\", \"Element\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Determine the statistical uncertainty of the measured peak energy. Add it to the table as a column named \"Energy unc. [keV]\". Then, remove the columns \"Net Area\" and \"FWHM [keV]\" from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the energy uncertainty.\n",
    "df[\"Energy unc. [keV]\"] = df[\"FWHM [keV]\"] / np.sqrt(8.*np.log(2)) / np.sqrt(df[\"Net Area\"])\n",
    "\n",
    "# Remove the \"Net Area\" and \"FWHM [keV]\" columns.\n",
    "df = df.drop(columns=[\"Net Area\", \"FWHM [keV]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Print the DataFrame. Display the peak energy uncertainty after the peak energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# Print the DataFrame.\n",
    "# The method to_string() is used to print the DataFrame without the index column, and\n",
    "#   to print all the rows without breaking the table.\n",
    "# The col_space parameter is used to set the minimum column width (in characters).\n",
    "df = df[['Sample', 'Energy [keV]', 'Energy unc. [keV]', 'Intensity [1/s]', 'Intensity unc. [1/s]', 'Line', 'Element', 'Z']]\n",
    "print(df.to_string(index=False, col_space=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Discuss the differences between the systematic and statistical uncertainties of the measured peak energy. Which one is dominant? Does some of them make the identification of the elements impossible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Solution:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Exclude alloys from the DataFrame above. Plot the intensities of the different single-element samples as a function of the proton number, $Z$, of the element. The intensity is a sum of the $\\mathrm{K}_\\alpha$ and $\\mathrm{K}_\\beta$ spectral line intensities. If they are not present, remove the sample. You can use the cell below to do the filtering for you. If you want to do the filtering in a different way (e.g. manually), feel free to create a new DataFrame in any way you like. Just call it `df_sum_intensities` so that the plotting cells work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Exclude alloys from the DataFrame.\n",
    "# Alloys are samples that contain more than one chemical element.\n",
    "# I.e. exclude samples that have the same sample number but the chemical elements are different in rows with the same sample number.\n",
    "# Group by Sample and Element and count unique elements per sample\n",
    "sample_element_counts = df.groupby('Sample')['Element'].nunique()\n",
    "\n",
    "# Get samples that have exactly one unique element\n",
    "single_element_samples = sample_element_counts[sample_element_counts == 1].index\n",
    "\n",
    "# Filter DataFrame to keep only those samples\n",
    "df_single_element = df[df['Sample'].isin(single_element_samples)]\n",
    "\n",
    "# Filter DataFrame to keep only samples with K lines\n",
    "df_single_element = df_single_element[df_single_element['Line'].str.contains('K')]\n",
    "\n",
    "# For each sample, calculate the sum of the alpha and beta spectral line intensities.\n",
    "# Create a new DataFrame with just one row per samples, and the sum of the intensities.\n",
    "# Sum the uncertainties in quadrature.\n",
    "df_sum_intensities = (df_single_element.groupby('Sample', as_index=False)\n",
    "                     .agg({\n",
    "                         'Element': 'first',\n",
    "                         'Z': 'first',\n",
    "                         'Intensity [1/s]': 'sum',\n",
    "                         'Intensity unc. [1/s]': lambda x: np.sqrt(np.sum(x**2))\n",
    "                     }))\n",
    "\n",
    "# Finally, remove Fe and Zn, as there are doubts about the measurements:\n",
    "#  - Fe measurement intensity is very low\n",
    "#  - Zn sample had Zn just on the surface, but it was scratched\n",
    "df_sum_intensities = df_sum_intensities.loc[~df_sum_intensities['Element'].isin(['Fe', 'Zn'])]\n",
    "\n",
    "# Print the result of the filtering and grouping.\n",
    "print(df_sum_intensities.to_string(index=False, col_space=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot(x, y, y_err, x_fit, y_fit, y_fit_lower, y_fit_upper, xlabel, ylabel):\n",
    "\n",
    "    # draw x, y with error bars\n",
    "    plt.errorbar(x, y, y_err, fmt='o', label='Data', color='black')\n",
    "\n",
    "    # draw the fit function and its uncertainty band\n",
    "    plt.fill_between(x_fit, y_fit_lower, y_fit_upper, color='red', alpha=0.3)\n",
    "\n",
    "    # create a legend entry for the fit function and its uncertainty band\n",
    "    line_with_band = mpl.lines.Line2D([], [], color='red', label='Fit', linestyle='-', linewidth=2)\n",
    "    band = mpl.patches.Patch(color='red', alpha=0.3, label='Fit uncertainty')\n",
    "\n",
    "    # get the current legend handles and labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles=handles + [(line_with_band, band)], labels=labels + ['Fit'])\n",
    "\n",
    "    # finally, plot\n",
    "    plt.plot(x_fit, y_fit, 'r-')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the intensity on Z dependence with a power law function: $I = a Z^b$.\n",
    "# Determine the parameters $a$ and $b$ and their uncertainties.\n",
    "# Plot the data points and the fitted function in the same plot.\n",
    "# Don't forget to take the correlation between the parameters into account when calculating the fit function uncertainty!\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import uncertainties\n",
    "import uncertainties.unumpy\n",
    "\n",
    "# Define the power law function\n",
    "def power_law(Z, a, b):\n",
    "    return a * (Z**b)\n",
    "\n",
    "# Fit the power law function to the data\n",
    "nom, cov = curve_fit(power_law, df_sum_intensities['Z'], df_sum_intensities['Intensity [1/s]'], sigma=df_sum_intensities['Intensity unc. [1/s]'], absolute_sigma=True)\n",
    "\n",
    "# Calculate the uncertainties of the fit parameters. Print the fit result.\n",
    "a, b = uncertainties.correlated_values(nom, cov)\n",
    "print(f'a = {a:.2uP}')\n",
    "print(f'b = {b:.2uP}')\n",
    "print(f'correlation coefficient: {cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1]):.3f}')\n",
    "\n",
    "# Evaluate the fit function at the integer values of Z\n",
    "Z_fit = np.linspace(df_sum_intensities['Z'].min(), df_sum_intensities['Z'].max(), 100)\n",
    "I_fit = power_law(Z_fit, a, b)\n",
    "I_fit_nom = uncertainties.unumpy.nominal_values(I_fit)\n",
    "I_fit_std = uncertainties.unumpy.std_devs(I_fit)\n",
    "\n",
    "# Plot the data and the fit function\n",
    "plot(df_sum_intensities['Z'], df_sum_intensities['Intensity [1/s]'], df_sum_intensities['Intensity unc. [1/s]'], \n",
    "     Z_fit, I_fit_nom, I_fit_nom - I_fit_std, I_fit_nom + I_fit_std, r'$Z$', r'$\\mathrm{Intensity}\\ [s^{-1}]$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ In the case of alloys, determine the samples’ chemical composition quantitatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# Filter DataFrame to keep only alloys.\n",
    "df_alloys = df[~df['Sample'].isin(single_element_samples)]\n",
    "\n",
    "# Print the DataFrame with alloys.\n",
    "print(df_alloys.to_string(index=False, col_space=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do anything fancy with the alloys, just copy their values.\n",
    "\n",
    "# Sample 5: Ag + Cu\n",
    "I_Cu = uncertainties.ufloat(5.49, 0.19)\n",
    "I_Ag = uncertainties.ufloat(47.0, 0.3) + uncertainties.ufloat(13.4, 0.2)\n",
    "\n",
    "# Print the intensities of Ag and Cu in the alloy\n",
    "print(f'Cu intensity in the alloy: ({I_Cu:.2uP}) s⁻¹')\n",
    "print(f'Ag intensity in the alloy: ({I_Ag:.2uP}) s⁻¹')\n",
    "\n",
    "# Reference intensities for Ag and Cu\n",
    "I_Cu_ref = uncertainties.ufloat(34.2, 0.2) # Measured in this experiment\n",
    "I_Ag_ref = power_law(47, a, b)\n",
    "\n",
    "# Print the reference intensities of Ag and Cu\n",
    "print(f'Cu reference intensity: ({I_Cu_ref:.2uP}) s⁻¹')\n",
    "print(f'Ag reference intensity: ({I_Ag_ref:.2uP}) s⁻¹')\n",
    "\n",
    "# Calculate normalization factor as we assume fraction(Cu)+fraction(Ag)=1\n",
    "norm = I_Cu_ref*I_Ag_ref/(I_Ag_ref*I_Cu+I_Cu_ref*I_Ag)\n",
    "\n",
    "# Print the fraction of Ag and Cu in the alloy\n",
    "print(f'Cu fraction in the alloy: {norm * I_Cu / (I_Cu_ref):.2uP}')\n",
    "print(f'Ag fraction in the alloy: {norm * I_Ag / (I_Ag_ref):.2uP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Task:}}$ Disscuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Solution:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\n",
    "[1] Thompson, A. C., *et al.*, X-Ray Data Booklet, 3rd ed. (rev. 2009). Lawrence Berkeley National Laboratory, Berkeley, CA. Available at https://xdb.lbl.gov/Section1/Table_1-2.pdf .\n",
    "\n",
    "[2] Basunia, M. S., Nucl. Data Sheets 107, 3323 (2006). DOI: 10.1016/j.nds.2006.07.001 , available at https://www.nndc.bnl.gov/ensdf/ ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum",
   "language": "python",
   "name": "praktikum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
