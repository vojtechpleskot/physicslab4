{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the string \"Your Name\" and \"DD.MM.YYYY\" with the appropriate values.\n",
    "\n",
    "from header import header\n",
    "_ = header(student=\"Your Name\", date=\"DD.MM.YYYY\", task_no=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifikace prvků na základě jejich charakteristického rentgenového záření."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pracovní úkoly  \n",
    "1. Proveďte energetickou kalibraci $\\gamma$-spektrometru pomocí $\\alpha$-zářiče $^{241}\\mathrm{Am}$.\n",
    "2. Určete materiál několika vzorků.\n",
    "3. Stanovte závislost četnosti rentgenového záření na atomovém čísle elementu.\n",
    "4. Určete relativní zastoupení prvků v jednom ze vzorků."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úvod\n",
    "\n",
    "Deexcitace vzbuzených stavů elektronového obalu je provázena emisí rentgenového záření. Protože energie tohoto záření je charakteristická pro daný prvek [1], lze jej využít ke kvalitativní i kvantitativní analýze složení materiálů. Elektronový obal lze excitovat několika způsoby. Rentgenová fluorescenční metoda využívá interakci fotonů s elektrony obalu: při fotoelektrickém jevu jsou elektrony vyráženy a obal se dostává do excitovaného stavu. Následná deexcitace vede k emisi charakteristických rentgenových čar.\n",
    "\n",
    "V našem experimentu měříme spektra vznikající při ozáření různých vzorků $\\gamma$–zářením z radioaktivního zdroje. Na základě energií rentgenových přechodů je možné identifikovat přítomné prvky a určit složení vzorku. Ke kvantitativnímu určení je nutné vyhodnotit i intenzity čar, které závisejí nejen na obsahu prvků, ale také na geometrii experimentu, tloušťce a složení vzorku, intenzitě buzení a vlastnostech detektoru. Citlivost metody je dána především energetickým rozlišením a účinností spektrometru.\n",
    "\n",
    "V našem experimentu je použitým zdrojem $\\gamma$–záření izotop $^{241}\\mathrm{Am}$. Jádra tohoto izotopu se $\\alpha$-rozpadem přeměňují na jádra $^{237}\\mathrm{Np}$, často ve vzbuzeném stavu. Při jejich deexcitaci vzniká několik $\\gamma$–linek [2], z nichž nejintenzivnější má energii $\\approx$ 59,5 keV. V měřeném spektru se navíc objevuje rentgenové záření dceřinného neptunia, především L-série v oblasti 10–20 keV.\n",
    "\n",
    "Radioaktivní zdroj je umístěn ve stojánku nad vzorkem, vedle detektoru. Směrem od zdroje k detektoru stojánek funguje jako stínění, zatímco mezi vzorkem a detektorem stínění není. Charakteristické rentgenové záření je detekováno polovodičovým spektrometrem, který se skládá z germaniového detektoru s beryliovým okénkem, nábojově citlivého předzesilovače, lineárního zesilovače, vysokonapěťového zdroje a USB datového akvizičního modulu. Detektor pracuje při napětí přibližně 3,5 kV.\n",
    "\n",
    "Energetické rozlišení spektrometru je FWHM $\\approx$ 0,7 keV v oblasti 5–60 keV. Kvůli tomuto relativně špatnému rozlišení a tlustému beryliovému okénku není možné registrovat záření s energiemi pod 4 keV. Proto nelze identifikovat prvky s protonovým číslem $Z < 20$, například příměsi hliníku, a výsledná analýza může být nepřesná.\n",
    "\n",
    "Vzhledem k energiím rentgenového záření a hustotám používaných vzorků je zřejmé, že zkoumáme jejich složení do hloubky několika desítek až málo stovek $\\mu\\text{m}$. Z hloubky větší než tři polotloušťky uniknou maximálně procenta vzniklého záření.\n",
    "\n",
    "$\\color{cyan}{\\textbf{TODO:}}$ citujme studijní text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postup měření\n",
    "\n",
    "Nakalibrujeme spektrometr radioaktivním zářičem $^{241}\\mathrm{Am}$. Dále naměříme spektra rentgenového záření několika různých vzorků, zpracujeme spektra a identifikujeme materiál či materiály vzorků pomocí tabulek energií rentgenového záření. Dobu jednotlivých měření volíme tak, aby nejistota výtěžku byla menší než 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Výsledky měření\n",
    "\n",
    "$\\color{red}{\\textbf{Úkol:}}$ Nakalibrujte spektrometr pomocí radioaktivního zářiče $^{241}\\mathrm{Am}$. Použijte tabelované energie singletních píků. Systematickou nejistotu kalibrace odhadněte pomocí multipletů $L$-série neptunia. Diskutujte výslednou kalibraci a její nejistoty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Řešení:}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Měřené vzorky jsou na první pohled kovy, předpokládejme, že jsou to buď jednoprvkové vzorky, nebo slitiny dvou prvků a to se $26 \\leq Z \\leq 52$.\n",
    "Určete chemické prvky v jednodruhových vzorcích. Vytvořte tabulku s číslem vzorku, naměřenou energií píku, čistou plochou píku, její nejistotou, FWHM, a časem měření. Dále do tabulky přidejte:\n",
    "\n",
    "- identifikovaný typ spektrální čáry (`K_a`, `K_b`, `K_a+b`, `L_a`, `L_b`, ...),\n",
    "\n",
    "- identifikovaný chemický prvek,\n",
    "\n",
    "- protonové číslo identifikovaného prvku.\n",
    "\n",
    "Každý řádek v tabulce odpovídá jedné spektrální čáře daného vzorku. Určete také chemické složení víceprvkových vzorků - slitin. Uveďte je také v tabulce (jeden řádek pro každou spektrální čáru každého prvku).\n",
    "Tabulku, resp. měřené hodnoty dále upravíme do podoby vhodné k další analýze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Řešení:}}$ \n",
    "1. Vepišme naměřená data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert experimental data into the list like so:\n",
    "# data = [\n",
    "#     [1,   9.42, 46161, 337, 0.75, 1000.1, \"K_a+b\", \"Ga\", 31],  # Ga; Z = 31\n",
    "#     ...\n",
    "# ]\n",
    "# Elements of inner list are (from screen or .Rpt files):\n",
    "# [\"ID\", \"CENTROID\", \"NET\", \"+/-\", \"FWHM\", \"MT\", \"Line\", \"Element\", \"Z\"]\n",
    "# tzn. [\"ID č.\", \"Energie (keV)\", \"Net Area\", \"nej. Net Area\", \"FWHM\", \"Meas. Time (s)\", \"Čára\", \"Prvek\", \"Z\"]\n",
    "#\n",
    "# Notes:\n",
    "#  - \"ID\" is an integer identifying the sample (1, 2, 3, ...).\n",
    "#  - \"Line\" supports the following values (case sensitive): \"K_a\", \"K_b\", \"K_a+b\", \"L_a\", \"L_b\", ...\n",
    "#  - \"MT\" is the measurement time in seconds (float). Use the live time value from the software.\n",
    "\n",
    "data = [\n",
    "    [1, ],\n",
    "    [2, ],\n",
    "    [3, ],\n",
    "    [4, ],\n",
    "    [5, ],\n",
    "    [6, ],\n",
    "    [9, ],\n",
    "    [11, ],\n",
    "    [10, ],\n",
    "    [12, ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vytvořme pandas DataFrame z listu dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from exp. data, set the column names.\n",
    "df = pd.DataFrame(data, columns=[\"ID\", \"CENTROID\", \"NET\", \"+/-\", \"FWHM\", \"MT\", \"Line\", \"Element\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Určete (statistickou) nejistotu naměřené energie. Přidejme ji do tabulky jako sloupec s názvem \"unc_CENTROID\". Poté z tabulky odstraňme dále nepotřebné sloupce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO calculate the energy uncertainty:\n",
    "df[\"unc_CENTROID\"] = \n",
    "# each sample is measured for different time, so we convert to 'per second' units\n",
    "df[\"Intensity\"] = df[\"NET\"] / df[\"MT\"]\n",
    "df[\"unc_Intensity\"] = df[\"+/-\"] / df[\"MT\"]\n",
    "\n",
    "# we can get rid of columns \"NET\", \"+/-\", and \"FWHM\" as we won't need them anymore\n",
    "df = df.drop(columns=[\"NET\", \"+/-\", \"FWHM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vypišme DataFrame. Pro přehlednost vypišme nejistotu energie píku za energii píku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the DataFrame.\n",
    "# The method to_string() is used to print the DataFrame without the index column\n",
    "#   and to print all rows without breaking the table.\n",
    "# The col_space parameter sets the minimum column width (in characters).\n",
    "cols = [\"ID\", \"Element\", \"Z\", \"CENTROID\", \"unc_CENTROID\", \"Line\", \"Intensity\", \"unc_Intensity\"]\n",
    "headers=[\"Vzorek\", \"Prvek\", \"Z\", \"E (keV)\", \"nej. E (keV)\", \"Čára\", \"I (s⁻¹)\", \"nej. I (s⁻¹)\"]\n",
    "print(df.round(3).to_string(index=False, col_space=7, columns=cols, header=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Diskutujte rozdíly mezi systematickými a statistickými nejistotami naměřených energií. Která z nich je dominantní? Znemožňuje některá z nich, či jejich kombinace jednoznačnou identifikaci prvků?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Řešení:}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Vytvořte tabulku, kde porovnáte měřené energie s tabelovanými. Porovnání diskutujte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# TODO add more elements/lines to the dictionary `theory` if need be.\n",
    "\n",
    "# Minimal theory table (keV).\n",
    "theory = {\n",
    "    'Cu': {'Ka1': 8.046,  'Ka2': 8.026,  'Kb1': 8.904,  'Kb2': 8.976,  'Kb3': 8.904},\n",
    "    'Sn': {'Ka1': 25.267,  'Ka2': 25.040,  'Kb1': 28.481,  'Kb2': 29.104,  'Kb3': 28.439},\n",
    "    'Rh': {'Ka1': 20.213,  'Ka2': 20.070,  'Kb1': 22.720,  'Kb2': 23.169,  'Kb3': 22.695},\n",
    "    'Ag': {'Ka1': 22.159,  'Ka2': 21.987,  'Kb1': 24.938,  'Kb2': 25.452,  'Kb3': 24.907},\n",
    "    'Zr': {'Ka1': 15.772,  'Ka2': 15.688,  'Kb1': 17.665,  'Kb2': 17.967,  'Kb3': 17.651},\n",
    "    'Mo': {'Ka1': 17.476,  'Ka2': 17.371,  'Kb1': 19.605,  'Kb2': 19.962,  'Kb3': 19.587},\n",
    "    'Cd': {'Ka1': 23.170,  'Ka2': 22.980,  'Kb1': 26.091,  'Kb2': 26.639,  'Kb3': 26.057},\n",
    "    'Zn': {'Ka1': 8.637,  'Ka2': 8.614,  'Kb1': 9.570,  'Kb2': 9.656,  'Kb3': 9.570},\n",
    "    'Fe': {'Ka1': 6.403,  'Ka2': 6.399,  'Kb1': 7.057,  'Kb2': np.nan,  'Kb3': 7.057},\n",
    "}\n",
    "\n",
    "# Function to compute weighted mean, ignoring NaN and None values.\n",
    "def weighted_mean(values, weights = None):\n",
    "\n",
    "    # Filter out None and NaN values.\n",
    "    vals = np.array([v for v in values if v is not None and np.isfinite(v)], dtype=float)\n",
    "\n",
    "    # If no valid values, return NaN.\n",
    "    if vals.size == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Use equal weights, when no weights are given.\n",
    "    if weights is None:\n",
    "        return float(np.mean(vals))\n",
    "    \n",
    "    # Remove weights corresponding to invalid values.\n",
    "    ws = np.array([w for v, w in zip(values, weights) if v is not None and np.isfinite(v)], dtype=float)\n",
    "    if ws.size == 0 or np.sum(ws) == 0:\n",
    "        return float(np.mean(vals))\n",
    "    \n",
    "    # Return weighted mean.\n",
    "    return float(np.sum(vals * ws) / np.sum(ws))\n",
    "\n",
    "# Weighted mean of Ka lines.\n",
    "# Ka1:Ka2 intensity ratio is approximately 2:1.\n",
    "def ka_mean(el, weights = [2.0, 1.0]):\n",
    "    d = theory.get(el, {})\n",
    "    return weighted_mean([d.get('Ka1'), d.get('Ka2')], weights = weights)\n",
    "\n",
    "# Weighted mean of Kb lines.\n",
    "def kb_mean(el, weights = None):\n",
    "    d = theory.get(el, {})\n",
    "    vals = [d.get('Kb1'), d.get('Kb2'), d.get('Kb3')]\n",
    "    if weights is None:\n",
    "        # equal weights, NaN are ignored\n",
    "        return weighted_mean(vals)\n",
    "    else:\n",
    "        return weighted_mean(vals, weights = weights)\n",
    "\n",
    "# Convert dict -> tidy DataFrame.\n",
    "rec = []\n",
    "for el, lines in theory.items():\n",
    "    rec.append({'Element': el,\n",
    "                'E_th_Ka_mean': ka_mean(el),  # Ka1:Ka2 is approximately 2:1.\n",
    "                'E_th_Kb_mean': kb_mean(el)})\n",
    "theory_df = pd.DataFrame(rec)\n",
    "\n",
    "# Merge theoretical values by Element.\n",
    "df2 = df.merge(theory_df, on = 'Element', how = 'left')\n",
    "\n",
    "# Normalize the Line labels.\n",
    "def norm_line(s):\n",
    "    s = str(s).lower().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "    if \"ka+b\" in s or (\"ka\" in s and \"kb\" in s):\n",
    "        return \"ka+b\"\n",
    "    if \"ka\" in s:\n",
    "        return \"ka\"\n",
    "    if \"kb\" in s:\n",
    "        return \"kb\"\n",
    "    return s  # fallback\n",
    "\n",
    "df2[\"Line_norm\"] = df2[\"Line\"].apply(norm_line)\n",
    "\n",
    "# What to display as \"theoretical energy\" (string) depending on the line:\n",
    "# - For K_a  : show the weighted Ka mean\n",
    "# - For K_b  : show Kb1\n",
    "# - For K_a+b: show \"Ka_mean / Kb1\" (so you see both); if you want a single centroid estimate,\n",
    "#              you could compute one using an assumed Kβ/Kα intensity ratio.\n",
    "def choose_theory_display(row):\n",
    "    if pd.isna(row[\"E_th_Ka_mean\"]):\n",
    "        return np.nan\n",
    "    if row[\"Line_norm\"] == \"ka\":\n",
    "        return f\"{row['E_th_Ka_mean']:.3f}\"\n",
    "    elif row[\"Line_norm\"] == \"kb\":\n",
    "        return f\"{row['E_th_Kb_mean']:.3f}\"\n",
    "    elif row[\"Line_norm\"] == \"ka+b\":\n",
    "        return f\"{row['E_th_Ka_mean']:.3f} / {row['E_th_Kb_mean']:.3f}\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df2[\"E_th (keV)\"] = df2.apply(choose_theory_display, axis = 1)\n",
    "\n",
    "# If you want a *single* theoretical number also for K_a and K_b rows (numeric),\n",
    "# we can keep numeric helpers and delta (measured - theoretical) where applicable:\n",
    "def numeric_theory(row):\n",
    "    E_a = row.get(\"E_th_Ka_mean\", np.nan)\n",
    "    E_b = row.get(\"E_th_Kb_mean\", np.nan)\n",
    "\n",
    "    if row[\"Line_norm\"] == \"ka\":\n",
    "        return E_a\n",
    "    if row[\"Line_norm\"] == \"kb\":\n",
    "        return E_b\n",
    "    if row[\"Line_norm\"] == \"ka+b\":\n",
    "        # assume intensity ratio Iβ/Iα = r\n",
    "        r = 0.15  # typical; adjust per element if needed\n",
    "        if np.isfinite(E_a) and np.isfinite(E_b):\n",
    "            return (E_a + r * E_b) / (1.0 + r)\n",
    "        else:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "df2[\"E_th_num\"] = df2.apply(numeric_theory, axis=1)\n",
    "df2[\"ΔE (meas-th)\"] = df2[\"CENTROID\"] - df2[\"E_th_num\"]\n",
    "\n",
    "# Columns to display: the original columns + the theoretical values and delta.\n",
    "# Improve the headers.\n",
    "cols_out = [\"ID\", \"Element\", \"Line\", \"CENTROID\", \"unc_CENTROID\", \"E_th (keV)\", \"ΔE (meas-th)\"]\n",
    "headers_out = [\"Vzorek\", \"Prvek\", \"Čára\", \"E (keV)\", \"nej. E (keV)\", \"E_th (keV)\", \"ΔE (keV)\"]\n",
    "\n",
    "# Print the requested table.\n",
    "print(df2.to_string(index = False, col_space = 8, columns = cols_out, header = headers_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Vyřaďte slitiny z výše uvedeného DataFrame. Vykreslete intenzity jednoprvkových vzorků jako funkci protonového čísla $Z$ prvku. Intenzita je součtem intenzit spektrálních čar $\\mathrm{K}_\\alpha$ a $\\mathrm{K}_\\beta$. Pokud nejsou přítomny, odeberte vzorek. K filtrování můžete použít buňku níže. Pokud chcete filtrování provést jiným způsobem (např. ručně), můžete vytvořit nový DataFrame libovolným způsobem. Pojmenujte jej `df_sum_intensities`, aby buňky pro vykreslení fungovaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Exclude alloys from the DataFrame.\n",
    "# Alloys are samples that contain more than one chemical element.\n",
    "# I.e. exclude samples that have the same sample number but the chemical elements are different in rows with the same sample number.\n",
    "# Group by Sample and Element and count unique elements per sample\n",
    "sample_element_counts = df.groupby('ID')['Element'].nunique()\n",
    "\n",
    "# Get samples that have exactly one unique element\n",
    "single_element_samples = sample_element_counts[sample_element_counts == 1].index\n",
    "\n",
    "# Filter DataFrame to keep only those samples\n",
    "df_single_element = df[df['ID'].isin(single_element_samples)]\n",
    "\n",
    "# Filter DataFrame to keep only samples with K lines\n",
    "df_single_element = df_single_element[df_single_element['Line'].str.contains('K')]\n",
    "\n",
    "# For each sample, calculate the sum of the alpha and beta spectral line intensities.\n",
    "# Create a new DataFrame with just one row per samples, and the sum of the intensities.\n",
    "# Sum the uncertainties in quadrature.\n",
    "df_sum_intensities = (df_single_element.groupby('ID', as_index=False)\n",
    "                     .agg({\n",
    "                         'Element': 'first',\n",
    "                         'Z': 'first',\n",
    "                         'Intensity': 'sum',\n",
    "                         'unc_Intensity': lambda x: np.sqrt(np.sum(x**2))\n",
    "                     }))\n",
    "\n",
    "# TODO Finally, remove samples if there are doubts about the measurements:\n",
    "df_sum_intensities = df_sum_intensities.loc[~df_sum_intensities['Element'].isin(['Gd', 'Pu'])]\n",
    "\n",
    "# Print the result of the filtering and grouping.\n",
    "print(df_sum_intensities.round(3).to_string(index=False, col_space=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napišme si obecnější funkci pro vykreslení grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(x, y, y_err, x_fit, y_fit, y_fit_lower, y_fit_upper, xlabel, ylabel):\n",
    "\n",
    "    # draw x, y with error bars\n",
    "    plt.errorbar(x, y, y_err, fmt='o', label='Data', color='black')\n",
    "\n",
    "    # draw the fit function and its uncertainty band\n",
    "    plt.fill_between(x_fit, y_fit_lower, y_fit_upper, color='red', alpha=0.3)\n",
    "\n",
    "    # create a legend entry for the fit function and its uncertainty band\n",
    "    line_with_band = mpl.lines.Line2D([], [], color='red', label='Fit', linestyle='-', linewidth=2)\n",
    "    band = mpl.patches.Patch(color='red', alpha=0.3, label='Fit uncertainty')\n",
    "\n",
    "    # get the current legend handles and labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles=handles + [(line_with_band, band)], labels=labels + ['Fit'])\n",
    "\n",
    "    # finally, plot\n",
    "    plt.plot(x_fit, y_fit, 'r-')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fitujme naše data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the intensity on Z dependence with a function.\n",
    "# TODO define the return value of the function. \n",
    "# Don't forget to use the numpy mathematical functions which work with arrays.\n",
    "def intensity_law(Z, a, b):\n",
    "    return \n",
    "\n",
    "# Determine the parameters and their uncertainties.\n",
    "# Plot the data points and the fitted function in the same plot.\n",
    "# Don't forget to take the correlation between the parameters into account when calculating the fit function uncertainty!\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import uncertainties\n",
    "import uncertainties.unumpy\n",
    "\n",
    "\n",
    "# Fit the power law function to the data\n",
    "nom, cov = curve_fit(intensity_law, df_sum_intensities['Z'], df_sum_intensities['Intensity'], sigma=df_sum_intensities['unc_Intensity'], absolute_sigma=True)\n",
    "\n",
    "# TODO Calculate the uncertainties of the fit parameters. Print the fit result.\n",
    "a, b = uncertainties.correlated_values(nom, cov)\n",
    "print(f'a = {a:.2uP}')\n",
    "print(f'b = {b:.2uP}')\n",
    "print(f'correlation coefficient: {cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1]):.3f}')\n",
    "\n",
    "# Evaluate the fit function on 100 values of Z-grid\n",
    "Z_fit = np.linspace(df_sum_intensities['Z'].min(), df_sum_intensities['Z'].max(), 100)\n",
    "I_fit = intensity_law(Z_fit, a, b)\n",
    "I_fit_nom = uncertainties.unumpy.nominal_values(I_fit)\n",
    "I_fit_std = uncertainties.unumpy.std_devs(I_fit)\n",
    "\n",
    "# Plot the data and the fit function\n",
    "plot(df_sum_intensities['Z'], df_sum_intensities['Intensity'], df_sum_intensities['unc_Intensity'], \n",
    "     Z_fit, I_fit_nom, I_fit_nom - I_fit_std, I_fit_nom + I_fit_std, r'$Z$', r'$\\mathrm{Intensity}\\ [s^{-1}]$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Pro slitiny určete kvantitativně složení vzorků.  \n",
    "Vytvořme si separátní DataFrame a vypišme si ho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to keep only alloys.\n",
    "df_alloys = df[~df['ID'].isin(single_element_samples)]\n",
    "\n",
    "# Print the DataFrame with alloys.\n",
    "print(df_alloys.round(3).to_string(index=False, col_space=7, columns=cols, header=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vzhledem k malému množství dat volíme pro slitiny manuální zpracování:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do anything fancy with the alloys, just copy their values.\n",
    "\n",
    "# TODO rewrite everything below according to Your findings\n",
    "\n",
    "#### EXAMPLE: ####\n",
    "# imagine we have a sample #420 made of Og and Tc\n",
    "# hardcode their intensities, already in units per second\n",
    "I_Og = uncertainties.ufloat(6.7, 0.2)\n",
    "I_Tc = uncertainties.ufloat(56.7, 0.85) + uncertainties.ufloat(12.3, 0.3)\n",
    "\n",
    "# Print the intensities of Og and Tc in the alloy\n",
    "print(f'Intenzita Og ve slitině: ({I_Og:.2uP}) s⁻¹')\n",
    "print(f'Intenzita Tc ve slitině: ({I_Tc:.2uP}) s⁻¹')\n",
    "\n",
    "# Intensities of pure Og and Tc samples. \n",
    "# Og shows case when we've measured pure sample,\n",
    "# Tc the case when we have not, so we need to estimate it from the fitted dependence\n",
    "I_Og_ref = uncertainties.ufloat(34.5, 0.14)\n",
    "I_Tc_ref = intensity_law(43, a, b)\n",
    "\n",
    "# Print the intensities of pure samples of Og a Tc.\n",
    "print(f'Intenzita čistého vzorku Og: ({I_Og_ref:.2uP}) s⁻¹')\n",
    "print(f'Intenzita čistého vzorku Tc: ({I_Tc_ref:.2uP}) s⁻¹')\n",
    "\n",
    "# TODO calculate the normalisation factor if need be\n",
    "norm = 1\n",
    "\n",
    "# Print the fraction of Og and Tc in the alloy\n",
    "print(f'Frakce Og ve slitině: {norm * I_Og / (I_Og_ref):.2uP}')\n",
    "print(f'Frakce Tc ve slitině: {norm * I_Tc / (I_Tc_ref):.2uP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Diskutujte měření a výsledky. Jakou funkci jste zvolili pro fitování dat a proč? Jaké vlivy jste při Vašem fitu zanedbali?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Řešení:}}$\n",
    "# Diskuse\n",
    "\n",
    "-> diskutujte zde <-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Úkol:}}$ Sepiš Závěr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\textbf{Řešení:}}$\n",
    "# Závěr\n",
    "\n",
    "-> závěrujte zde <-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literatura\n",
    "\n",
    "[1] Thompson, A. C., *et al.*, X-Ray Data Booklet, 3rd ed. (rev. 2009). Lawrence Berkeley National Laboratory, Berkeley, CA. Dostupné na https://xdb.lbl.gov/Section1/Table_1-2.pdf .\n",
    "\n",
    "[2] Basunia, M. S., Nucl. Data Sheets 107, 3323 (2006). DOI: 10.1016/j.nds.2006.07.001 , dostupné na https://www.nndc.bnl.gov/ensdf/ ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praktikum",
   "language": "python",
   "name": "praktikum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
